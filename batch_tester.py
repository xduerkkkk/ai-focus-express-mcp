from web_utils import get_page_content_and_date

from datetime import datetime, timezone, timedelta
import time

# ==============================================================================
# è¿™æ˜¯ä½ æä¾›çš„æµ‹è¯•å‡½æ•°ï¼Œæˆ‘ä»¬æŠŠå®ƒæ”¾åœ¨è¿™é‡Œï¼Œæ–¹ä¾¿ç»Ÿä¸€æ‰§è¡Œ
# ==============================================================================
def test_source_compatibility(url, category):
    """æµ‹è¯•å•ä¸ªä¿¡æ¯æºæ˜¯å¦å…¼å®¹æˆ‘ä»¬çš„è§£æå‡½æ•°"""
    print(f"\n--- [{category}] æ­£åœ¨æµ‹è¯•: {url} ---")
    
    # è®¾å®šä¸€ä¸ªè¾ƒå®½æ¾çš„æ—¶é—´èŒƒå›´ä»¥å¢åŠ æ‰¾åˆ°æ–‡ç« çš„å‡ ç‡
    time_limit = datetime.now(timezone.utc) - timedelta(days=90) 
    
    try:
        # æ ¸å¿ƒè°ƒç”¨ï¼šä½¿ç”¨ä½ çš„è§£æå‡½æ•°
        # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ç¯‡å®é™…çš„æ–‡ç« æ¥æµ‹è¯•ï¼Œè€Œä¸æ˜¯åšå®¢é¦–é¡µã€‚
        # ä¸€ä¸ªå°æŠ€å·§ï¼šä½¿ç”¨Googleæœç´¢æ¥è‡ªåŠ¨å¯»æ‰¾è¯¥ç½‘ç«™ä¸Šçš„ä¸€ç¯‡æ–‡ç« URL
        from googlesearch import search
        # æŸ¥æ‰¾è¯¥ç½‘ç«™ä¸Šä»»æ„ä¸€ç¯‡å…³äº "AI" çš„æ–‡ç« æ¥æµ‹è¯•
        query = f'"AI" site:{url}'
        # æˆ‘ä»¬åªéœ€è¦ä¸€ä¸ªURLæ¥æµ‹è¯•å³å¯
        test_url = next(search(query, num_results=1, lang="en"), None)

        if not test_url:
            print(f"ğŸŸ¡ {url} - è­¦å‘Š: æ— æ³•é€šè¿‡æœç´¢è‡ªåŠ¨æ‰¾åˆ°æµ‹è¯•æ–‡ç« ï¼Œè·³è¿‡ã€‚")
            return

        print(f"   (ä½¿ç”¨æ–‡ç« é“¾æ¥è¿›è¡Œæµ‹è¯•: {test_url[:70]}...)")
        result = get_page_content_and_date(test_url, time_limit)
        
        if result:
            title, date, summary = result
            print(f"âœ… {url} - æˆåŠŸè§£æ")
            print(f"   æ ‡é¢˜: {title[:50]}...")
            print(f"   æ—¥æœŸ: {date.strftime('%Y-%m-%d')}")
            print(f"   æ‘˜è¦: {summary.strip()[:100]}...")
        else:
            print(f"âŒ {url} - è§£æå¤±è´¥ (å‡½æ•°è¿”å›Noneï¼Œå¯èƒ½æ—¥æœŸè¿‡æ—§æˆ–æ— æ³•æå–å†…å®¹)")

    except Exception as e:
        print(f"ğŸ’¥ {url} - å‡ºç°ä¸¥é‡é”™è¯¯: {e}")

# ==============================================================================
# AI ä¿¡æ¯æºä»“åº“ (URL REGISTRY)
# ==============================================================================
SOURCES_TO_TEST = {
    "é¡¶çº§å…¬å¸åšå®¢ (Top-Tier Company Blogs)": [
        "openai.com/blog",
        "huggingface.co/blog",
        "ai.googleblog.com",
        "developer.nvidia.com/blog",
        "ai.meta.com/blog/",
        "blogs.microsoft.com/ai/",
        "deepmind.google/blog/",
        "anthropic.com/news",
        "mistral.ai/news/"
    ],
    "AIä¸“ä¸šæ–°é—»ä¸ç¤¾åŒº (AI-focused News & Community)": [
        "marktechpost.com",
        "unite.ai",
        "analyticsvidhya.com/blog",
        "kdnuggets.com",
        "towardsdatascience.com" # (åœ¨Mediumä¸Šï¼Œå¯èƒ½ä¼šæœ‰è§£æå›°éš¾)
    ],
    "ä¸»æµç§‘æŠ€åª’ä½“ (Major Tech Outlets)": [
        "techcrunch.com/category/artificial-intelligence/",
        "venturebeat.com/category/ai/",
        "arstechnica.com/information-technology/artificial-intelligence/",
        "wired.com/tag/artificial-intelligence/"
    ],
    "äº‘ä¸ç¡¬ä»¶å‚å•† (Cloud & Hardware Vendors)": [
        "aws.amazon.com/blogs/machine-learning/",
        "apple.com/machine-learning/research/",
        "blogs.oracle.com/ai/"
    ]
}

# ==============================================================================
# ä¸»æ‰§è¡Œå‡½æ•° (MAIN EXECUTOR)
# ==============================================================================
def main():
    print("="*50)
    print("  AI ä¿¡æ¯æºå…¼å®¹æ€§è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬")
    print("="*50)
    
    for category, urls in SOURCES_TO_TEST.items():
        for url in urls:
            test_source_compatibility(url, category)
            time.sleep(2) # å¢åŠ å»¶æ—¶ï¼Œå°Šé‡å¯¹æ–¹æœåŠ¡å™¨ï¼Œé¿å…è¢«å°ç¦

    print("\n\n" + "="*50)
    print("  æ‰€æœ‰æµ‹è¯•å·²å®Œæˆï¼")
    print("  è¯·æ£€æŸ¥ä¸Šé¢çš„ 'âœ… æˆåŠŸè§£æ' åˆ—è¡¨ï¼Œ")
    print("  å¹¶å°†è¿™äº›ç½‘å€æ›´æ–°åˆ°ä½ çš„ sources.json æ–‡ä»¶ä¸­ã€‚")
    print("="*50)

if __name__ == "__main__":
    main()